{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import quimb as qu\n",
    "import quimb.tensor as qtn\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import joblib\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "import multiprocessing\n",
    "import time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('2.0.0', '1.3.0', '1.18.5')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__, qu.__version__, np.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$ham = scale_x * \\sum_{i=1}^{N-1}{\\boldsymbol{\\sigma}_{x}^{i}\\cdot\\boldsymbol{\\sigma}_{x}^{i + 1}} + scale_y * \\sum_{i=1}^{N-1}{\\boldsymbol{\\sigma}_{y}^{i}\\cdot\\boldsymbol{\\sigma}_{y}^{i + 1}} + scale_z * \\sum_{i=1}^{N-1}{\\boldsymbol{\\sigma}_{z}^{i}\\cdot\\boldsymbol{\\sigma}_{z}^{i + 1}}$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the scales that defines the hamiltonian\n",
    "scale_x, scale_y, scale_z = 1, 0.5, 0.8\n",
    "# whether to apply symmetry to the circuit to reduce parameters number\n",
    "symmetry_apply = False\n",
    "# number of cpu that are going to use\n",
    "num_cpus = 1\n",
    "# the system size \n",
    "N = 10\n",
    "# how many layers are going to be implement (1, 2, ... layers)\n",
    "layers = 5\n",
    "# how many runs for each set up\n",
    "runs = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define gates\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ry_(param):\n",
    "    return tf.convert_to_tensor([[tf.cos(param / 2), -tf.sin(param / 2)],\n",
    "                                 [tf.sin(param / 2),\n",
    "                                  tf.cos(param / 2)]])\n",
    "\n",
    "\n",
    "def rz_(param):\n",
    "    return tf.convert_to_tensor([[tf.exp(-1j * param / 2), 0],\n",
    "                                 [0, tf.exp(1j * param / 2)]])\n",
    "\n",
    "\n",
    "def phase_gate_(param):\n",
    "    return tf.convert_to_tensor([[1, 0], [0, tf.exp(1j * param)]])\n",
    "\n",
    "\n",
    "def cnot_(reverse=False):\n",
    "    if reverse:\n",
    "        return tf.constant(qu.permute(qu.CNOT(), [2, 2], perm=[1, 0]))\n",
    "    else:\n",
    "        return tf.constant(qu.CNOT())\n",
    "\n",
    "def noisy_cnot_(noise, reverse=False):\n",
    "    noisy_cz = np.sqrt(1j) * qu.expm(1j * qu.kron(\n",
    "        qu.pauli('Z'), qu.pauli('I')) @ np.kron(qu.pauli('I'), qu.pauli('Z')) *\n",
    "                                     (np.pi / 4 + noise)) @ qu.kron(\n",
    "                                         qu.Rz(np.pi / 2), qu.Rz(np.pi / 2))\n",
    "    if reverse == False:\n",
    "        noisy_cnot = qu.kron(qu.pauli('I'), qu.hadamard()) @ noisy_cz @ qu.kron(\n",
    "            qu.pauli('I'), qu.hadamard())\n",
    "    else:\n",
    "        noisy_cnot = qu.kron(qu.hadamard(), qu.pauli('I')) @ noisy_cz @ qu.kron(\n",
    "            qu.hadamard(), qu.pauli('I'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The circuit of \n",
    "# $$\\mathcal{N}(\\theta_x, \\theta_y, \\theta_z) = e^{i\\left(\\theta_x \\sigma_{x} \\otimes \\sigma_{x} + \\theta_y \\sigma_{y} \\otimes \\sigma_{y} + \\theta_z \\sigma_{z} \\otimes \\sigma_{z}\\right)}$$\n",
    "the circuit figure can be check on our paper arXiv:2006.09415, or the original paper https://doi.org/10.1103/PhysRevA.69.032315"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def N_block(psi, params_block, wires):\n",
    "    theta_x = scale_x * params_block\n",
    "    theta_y = scale_y * params_block\n",
    "    theta_z = scale_z * params_block\n",
    "    \n",
    "    theta_x = 2 * theta_x - np.pi / 2\n",
    "    theta_y = 2 * theta_y - np.pi / 2\n",
    "    theta_z = 2 * theta_z - np.pi / 2\n",
    "\n",
    "    psi.gate_(rz_(-np.pi / 2), wires[1], tags='RZ')\n",
    "\n",
    "    psi.gate_(cnot_(reverse=True), wires, tags='CNOT')\n",
    "\n",
    "    psi.gate_(rz_(-theta_z), wires[0], tags='RZ')\n",
    "\n",
    "    psi.gate_(ry_(theta_x), wires[1], tags='RY')\n",
    "\n",
    "    psi.gate_(cnot_(reverse=False), wires, tags='CNOT')\n",
    "\n",
    "    psi.gate_(ry_(-theta_y), wires[1], tags='RY')\n",
    "\n",
    "    psi.gate_(cnot_(reverse=True), wires, tags='CNOT')\n",
    "\n",
    "    psi.gate_(rz_(np.pi / 2), wires[0], tags='RZ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The ansatz circuit\n",
    "The circuit figure can be check on our paper arXiv:2006.09415"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ansatz(psi, params, num_layer, N):\n",
    "    # split all the params to the N function params and rotation params\n",
    "    params_block = params[0]\n",
    "    params_rot = params[1]\n",
    "    # copy |psi> manually to avoid any operation happens on the psi0\n",
    "    psi = psi.copy()\n",
    "\n",
    "    # apply the gates layer-wise \n",
    "    for i in range(num_layer):\n",
    "        for j in range(0, N, 2):\n",
    "            N_block(psi,\n",
    "                       params_block[i][j],\n",
    "                       wires=[j, j + 1])\n",
    "        for j in range(1, N - 1, 2):\n",
    "            N_block(psi,\n",
    "                   params_block[i][j],\n",
    "                   wires=[j, j + 1])\n",
    "        # if apply symmetry rotation params will cut down to half\n",
    "        # where \\theta_{0} = -\\theta_{N - 1}\n",
    "        if symmetry_apply:\n",
    "            for j in range(N // 2):\n",
    "                psi.gate_(phase_gate_(params_rot[i][j]), j, tags='ROT')\n",
    "                psi.gate_(phase_gate_(-params_rot[i][j]), N - j - 1, tags='ROT')\n",
    "        else:\n",
    "            for j in range(N):\n",
    "                psi.gate_(phase_gate_(params_rot[i][j]), j, tags='ROT')\n",
    "    return psi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tensor network fidelity function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fidelity_tn(state1, state2):\n",
    "    return np.abs((state1 & state2).contract(all,\n",
    "                                             optimize='random-greedy',\n",
    "                                             backend='tensorflow').numpy())**2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tensor network expectation value function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def expt_val(psi, H):\n",
    "    energy = qtn.TensorNetwork(qtn.align_TN_1D(psi.H, H, psi))\n",
    "    return energy.contract(all, optimize='random-greedy', backend='tensorflow')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tool function (to change the inner data of tensors to complex128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_to_data(*objs):\n",
    "    for obj in objs:\n",
    "        for t in obj:\n",
    "            t.modify(data=tf.constant(t.data, dtype=tf.complex128))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# For ignore the warning information of tensorflow (only use this when you sure the code is ok)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "tf.get_logger().setLevel(logging.ERROR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main training logic "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def train_process(psi0, H, gs, N, num_layer, run, epoch=-1, tol=1e-4):\n",
    "    print(\n",
    "        'Run={}, N={}, num_layer={} scale={}/{}/{} symmetry={} training begin.'.\n",
    "        format(run, N, num_layer, scale_x, scale_y, scale_z, symmetry_apply))\n",
    "    # to avoid the random params are the same if you using multi-process\n",
    "    # mannully reset the numpy random seed\n",
    "    np.random.seed()\n",
    "\n",
    "    # to store all the intermediate results\n",
    "    params_gd = []\n",
    "    expt_gd = []\n",
    "    fidelity_gd = []\n",
    "\n",
    "    # randomly generate the initial params\n",
    "    params = tf.Variable(np.random.randn(2, num_layer, N))\n",
    "\n",
    "    # define the optimizer\n",
    "    # here we use adam with amsgrad applied\n",
    "    opt = tf.keras.optimizers.Adam(learning_rate=0.01,\n",
    "                                   beta_1=0.9,\n",
    "                                   beta_2=0.999,\n",
    "                                   epsilon=1e-8,\n",
    "                                   amsgrad=True)\n",
    "\n",
    "    for index in range(1, epoch + 1):\n",
    "        with tf.GradientTape() as tape:\n",
    "            # cast params into complex data type otherwise tensorflow won't work\n",
    "            newparams = tf.complex(params, tf.constant(0, dtype=tf.float64))\n",
    "            # evolve the system\n",
    "            psi = ansatz(psi0, newparams, num_layer, N)\n",
    "            # calculate the loss, in this case, the expectation value\n",
    "            loss = expt_val(psi, H)\n",
    "        # tensorflow gradient functions\n",
    "        gradients = tape.gradient(loss, params)\n",
    "        opt.apply_gradients(zip([gradients], [params]))\n",
    "\n",
    "        # record the intermediate results\n",
    "        params_gd.append(params.numpy())\n",
    "        expt_gd.append(4 * loss.numpy().real)\n",
    "        fidelity_gd.append(fidelity_tn(gs, psi))\n",
    "\n",
    "        if index % 50 == 0:\n",
    "            print(\n",
    "                \"Run={}, N={}, num_layer={}, scale={}/{}/{}, step {}: expt: {:.3f}, fidelity: {:.3f}\"\n",
    "                .format(run, N, num_layer, scale_x, scale_y, scale_z, index,\n",
    "                        expt_gd[-1], fidelity_gd[-1]))\n",
    "\n",
    "    # Store the data\n",
    "    joblib.dump(\n",
    "        params_gd,\n",
    "        'xxz/random_scheme_data/params_run={}_N={}_layer={}_epoch={}_scale={}{}{}_symmetry={}'\n",
    "        .format(run, N, num_layer, (-1 if epoch == int(1e8) else epoch),\n",
    "                scale_x, scale_y, scale_z, symmetry_apply))\n",
    "    joblib.dump(\n",
    "        expt_gd,\n",
    "        'xxz/random_scheme_data/expt_run={}_N={}_layer={}_epoch={}_scale={}{}{}_symmetry={}'\n",
    "        .format(run, N, num_layer, (-1 if epoch == int(1e8) else epoch),\n",
    "                scale_x, scale_y, scale_z, symmetry_apply))\n",
    "    joblib.dump(\n",
    "        fidelity_gd,\n",
    "        'xxz/random_scheme_data/fidelity_run={}_N={}_layer={}_epoch={}_scale={}{}{}_symmetry={}'\n",
    "        .format(run, N, num_layer, (-1 if epoch == int(1e8) else epoch),\n",
    "                scale_x, scale_y, scale_z, symmetry_apply))\n",
    "    return fidelity_gd[-1], index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# multiprocessing pool. \n",
    "pool = multiprocessing.Pool(num_cpus)\n",
    "\n",
    "# not knowing why, but this part need to be out of the for-loop \n",
    "# to make the multi-process work. Your case might be varied.\n",
    "# define the |psi0> which is |0101...01>\n",
    "psi0 = qtn.MPS_computational_state('01' * (N // 2))\n",
    "# define the ham which scale settings\n",
    "H = qtn.MPO_ham_heis(N, j=(scale_x, scale_y, scale_z))\n",
    "# calculate the ground state then convert it to tensor network\n",
    "gs = qtn.Dense1D(\n",
    "        qu.groundstate(qu.ham_heis(N, j=(scale_x, scale_y, scale_z), cyclic=False, sparse=True)))\n",
    "# convert the inner data type to tf.complex128 to make the code work\n",
    "apply_to_data(psi0, H, gs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# run defines how many runs the code is going to run\n",
    "for run in range(1, runs + 1):\n",
    "    for num_layer in range(1, layers + 1):\n",
    "        if symmetry_apply:\n",
    "            params_number = num_layer * ((N * 3) // 2 - 1)\n",
    "        else:\n",
    "            params_number = num_layer * (2 * N - 1)\n",
    "        # we set the training iteration to be 50 * number_of_params\n",
    "        epoch = params_number * 50\n",
    "        try:\n",
    "            pool.apply_async(train_process, args=(psi0, H, gs, N, num_layer, run, epoch, 1e-4, ))\n",
    "        except:\n",
    "            print(\"Error!!!\")\n",
    "# have to run this 2 lines after using multi-processing pool\n",
    "pool.close()\n",
    "pool.join()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Conda (quantum)",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "toc-autonumbering": false,
  "toc-showcode": true,
  "toc-showmarkdowntxt": true,
  "toc-showtags": false
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
